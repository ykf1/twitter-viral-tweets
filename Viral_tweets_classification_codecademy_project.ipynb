{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and examine the dataset\n",
    "import pandas as pd\n",
    "\n",
    "all_tweets = pd.read_json(r'C:/Users/Yeo Kheng Feng/Desktop/twitter_classification_project/random_tweets.json', encoding = \"Latin-1\", lines=True)\n",
    "\n",
    "print(len(all_tweets))\n",
    "print(all_tweets.columns)\n",
    "print(all_tweets.loc[0]['text']) # The 'text' column contain the tweet\n",
    "\n",
    "#Print the 'user' column here.\n",
    "print(all_tweets.loc[0][\"user\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a viral tweet\n",
    "print(all_tweets[\"retweet_count\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_tweets['is_viral'] = np.where(all_tweets['retweet_count'] > 429, 1, 0)\n",
    "print(all_tweets['is_viral'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making features\n",
    "\n",
    "all_tweets['tweet_length'] = all_tweets.apply(lambda tweet: len(tweet['text']), axis=1)\n",
    "all_tweets['followers_count'] = all_tweets.apply(lambda tweet: tweet['user']['followers_count'], axis=1)\n",
    "all_tweets['friends_count'] = all_tweets.apply(lambda tweet: tweet['user']['friends_count'], axis=1)\n",
    "all_tweets['hashtags_count'] = all_tweets.apply(lambda tweet: tweet['text'].count('\\#'), axis=1)\n",
    "all_tweets['links_count'] = all_tweets.apply(lambda tweet: tweet['text'].count('http'), axis=1)\n",
    "all_tweets['words_count'] = all_tweets.apply(lambda tweet: len(tweet['text'].split()), axis=1)\n",
    "all_tweets['average_length_count'] = all_tweets.apply(lambda tweet: sum(len(word) for word in tweet['text'].split()) / len(tweet['text'].split()) , axis=1)\n",
    "print(all_tweets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine features relationship with labels\n",
    "features = ['tweet_length', 'followers_count', 'friends_count', 'hashtags_count', 'words_count', 'links_count', 'average_length_count']\n",
    "for feature in features:\n",
    "    print('Correlation coefficient of retweet_counts with ' + feature + ': ' + str(round(np.corrcoef(all_tweets['retweet_count'], all_tweets[feature])[0,1], 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the data\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "labels = all_tweets['is_viral']\n",
    "data = all_tweets[['tweet_length', 'followers_count', 'friends_count', 'hashtags_count', 'words_count', 'links_count', 'average_length_count']]\n",
    "scaled_data = scale(data, axis=0)\n",
    "print(data.loc[0])\n",
    "print(scaled_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(scaled_data, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(train_data, train_labels)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "predictions = log_reg.predict(test_data)\n",
    "print(accuracy_score(test_labels, predictions))\n",
    "print(recall_score(test_labels, predictions))\n",
    "print(precision_score(test_labels, predictions))\n",
    "print(f1_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train k-Nearest neighbors model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = []\n",
    "for k in range(1, 500):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(train_data, train_labels)\n",
    "    scores.append(classifier.score(test_data, test_labels))\n",
    "\n",
    "# Print classifier accuracy over a range of k\n",
    "plt.plot(range(1,500), scores)\n",
    "plt.xlabel('k neighbors')\n",
    "plt.ylabel('Classifier Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1, 20):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "    classifier.fit(train_data, train_labels)\n",
    "    scores.append(classifier.score(test_data, test_labels))\n",
    "    \n",
    "plt.plot(range(1,20), scores)\n",
    "plt.xlabel('k neighbors')\n",
    "plt.ylabel('Classifier Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "\n",
    "#svm_clf = SVC(kernel='poly', degree=3, coef0=1, C=5)\n",
    "#svm_clf.fit(train_data, train_labels)\n",
    "#svm_clf.score(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import VotingClassifier\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "#log_clf = LogisticRegression()\n",
    "#knn_clf = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "#voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf)], voting='hard')\n",
    "#voting_clf.fit(train_data, train_labels)\n",
    "\n",
    "#for clf in (log_clf, knn_clf, voting_clf):\n",
    " #   clf.fit(train_data, train_labels)\n",
    "  #  y_pred = clf.predict(test_data)\n",
    "   # print(accuracy_score(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
